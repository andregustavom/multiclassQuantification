{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from DyS_cvx import build_histograms\n",
    "\n",
    "import utils as qntu\n",
    "\n",
    "import os.path\n",
    "import pickle\n",
    "\n",
    "import pdb\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantifiers.ACC import ACC\n",
    "from quantifiers.PCC import PCC\n",
    "from quantifiers.PACC import PACC\n",
    "from quantifiers.HDy import HDy\n",
    "from quantifiers.X import X\n",
    "from quantifiers.MAX import MAX\n",
    "from quantifiers.SMM import SMM  \n",
    "from quantifiers.DyS import DyS\n",
    "from quantifiers.SORD import SORD\n",
    "from quantifiers.MS import MS\n",
    "from quantifiers.T50 import T50\n",
    "from quantifiers.EMQ import EMQ\n",
    "from quantifiers.CC import CC\n",
    "from quantifiers.DySyn import DySyn\n",
    "from quantifiers.MS2 import MS2\n",
    "\n",
    "\n",
    "def apply_quantifier(qntMethod, p_score, n_score,test_score, TprFpr, thr, measure, calib_clf, X_test, u_p, u_n):\n",
    "  if qntMethod == \"CC\":\n",
    "    return CC(test_score, thr)\n",
    "  if qntMethod == \"ACC\":        \n",
    "    return ACC(test_score, TprFpr)\n",
    "  if qntMethod == \"EMQ\":\n",
    "    tr_dist = [len(p_score), len(n_score)]\n",
    "    tr_dist = np.round(tr_dist/np.sum(tr_dist),4)\n",
    "    test_score = pd.concat([pd.DataFrame(test_score), pd.DataFrame(1-test_score)], axis=1)\n",
    "    test_score.columns = ['1', '0']\n",
    "    return EMQ(tr_dist, np.array(test_score))\n",
    "  if qntMethod == \"SMM\":\n",
    "    return SMM(p_score, n_score, test_score)\n",
    "  if qntMethod == \"HDy\":\n",
    "    return HDy(p_score, n_score, test_score)\n",
    "  if qntMethod == \"DyS\":\n",
    "    return DyS_SCH_cvx(p_score, n_score, test_score, measure)\n",
    "  if qntMethod == \"DySyn\":\n",
    "    return DySyn(test_score)\n",
    "  if qntMethod == \"DySyn2\":\n",
    "    return DySyn2(test_score)\n",
    "  if qntMethod == \"DySyn+aMoSS\":\n",
    "    return DySyn2_aMoSS(test_score, u_p, u_n)\n",
    "  if qntMethod == \"SORD\":\n",
    "    return SORD(p_score, n_score, test_score)\n",
    "  if qntMethod == \"MS\":\n",
    "    return MS(test_score, TprFpr)\n",
    "  if qntMethod == \"MAX\":\n",
    "    return MAX(test_score, TprFpr)\n",
    "  if qntMethod == \"X\":\n",
    "    return X(test_score, TprFpr)\n",
    "  if qntMethod == \"T50\":\n",
    "    return T50(test_score, TprFpr)\n",
    "  if qntMethod == \"PCC\":\n",
    "    return PCC(calib_clf, X_test,thr)\n",
    "  if qntMethod == \"PACC\":\n",
    "    return PACC(calib_clf, X_test, TprFpr, thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DyS_SCH(pos_scores, neg_scores, test_scores, measure='topose'):\n",
    "    \n",
    "    #bin_size = np.linspace(10,10,1)\n",
    "    bin_size = np.linspace(2,20,10)\n",
    "    #bin_size = np.linspace(2,10,9)  #[10,20] range(10,111,10) #creating bins from 2 to 10 with step size 2\n",
    "    bin_size = np.append(bin_size, 30)\n",
    "    bin_size = bin_size.astype(int)\n",
    "    \n",
    "    result  = []\n",
    "    score_range = (np.min(neg_scores), np.max(pos_scores))\n",
    "    for bins in bin_size:\n",
    "        #....Creating Histograms bins score\\counts for validation and test set...............\n",
    "        \n",
    "        p_bin_count = np.histogram(pos_scores, bins=bins, range=score_range)[0]/len(pos_scores)\n",
    "        n_bin_count = np.histogram(neg_scores, bins=bins, range=score_range)[0]/len(neg_scores)\n",
    "        te_bin_count = np.histogram(test_scores, bins=bins, range=score_range)[0]/len(test_scores)\n",
    "\n",
    "        #for x in range(0,len(alpha_values),1):\n",
    "            \n",
    "        #    vDist.append(qntu.DyS_distance(((p_bin_count*alpha_values[x]) + (n_bin_count*(1-alpha_values[x]))), te_bin_count, measure=measure))\n",
    "\n",
    "        #result.append(alpha_values[np.argmin(vDist)])\n",
    "        \n",
    "        def f(x):            \n",
    "            return(qntu.DyS_distance(((p_bin_count*x) + (n_bin_count*(1-x))), te_bin_count, measure = measure))\n",
    "    \n",
    "        result.append(qntu.TernarySearch(0, 1, f))                                           \n",
    "                        \n",
    "    pos_prop = round(np.median(result),2)\n",
    "    return pos_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cvxpy as cvx\n",
    "\n",
    "def DyS_SCH_cvx(pos_scores, neg_scores, test_scores, measure='topose'):\n",
    "    \n",
    "    #bin_size = np.linspace(10,10,1)\n",
    "    bin_size = np.linspace(2,20,10)\n",
    "    #bin_size = np.linspace(2,10,9)  #[10,20] range(10,111,10) #creating bins from 2 to 10 with step size 2\n",
    "    bin_size = np.append(bin_size, 30)\n",
    "    bin_size = bin_size.astype(int)\n",
    "    \n",
    "    result  = []\n",
    "    score_range = (np.min(neg_scores), np.max(pos_scores))\n",
    "    for bins in bin_size:\n",
    "        #....Creating Histograms bins score\\counts for validation and test set...............\n",
    "        \n",
    "        p_bin_count = np.histogram(pos_scores, bins=bins, range=score_range)[0]/len(pos_scores)\n",
    "        n_bin_count = np.histogram(neg_scores, bins=bins, range=score_range)[0]/len(neg_scores)\n",
    "        te_bin_count = np.histogram(test_scores, bins=bins, range=score_range)[0]/len(test_scores)\n",
    "\n",
    "        #for x in range(0,len(alpha_values),1):\n",
    "            \n",
    "        #    vDist.append(qntu.DyS_distance(((p_bin_count*alpha_values[x]) + (n_bin_count*(1-alpha_values[x]))), te_bin_count, measure=measure))\n",
    "\n",
    "        #result.append(alpha_values[np.argmin(vDist)])\n",
    "        \n",
    "        #def f(x):            \n",
    "        #    return(qntu.DyS_distance(((p_bin_count*x) + (n_bin_count*(1-x))), te_bin_count, measure = measure))\n",
    "        CM = np.concatenate([[n_bin_count], [p_bin_count]]).T\n",
    "        \n",
    "        p = cvx.Variable(2)\n",
    "        constraints = [p >= 0, cvx.sum(p) == 1.0]\n",
    "        problem = cvx.Problem(cvx.Minimize(cvx.sum(cvx.kl_div(2 * CM @ p, te_bin_count) +\n",
    "                                                   cvx.kl_div(2 * te_bin_count, CM @ p))),\n",
    "                              constraints)\n",
    "        problem.solve(max_iters=10000)\n",
    "        result.append(p.value[0])\n",
    "        #result.append(qntu.TernarySearch(0, 1, f))                                           \n",
    "                        \n",
    "    pos_prop = round(np.median(result),2)\n",
    "    return pos_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch (label, alpha, X_test, y_test, n):\n",
    "    \n",
    "    n_pos = int(np.round(n*alpha,0))\n",
    "    n_neg = n - n_pos \n",
    "    \n",
    "    i_pos = np.where(y_test == label)\n",
    "    #X_pos = X_test.iloc[i_pos]\n",
    "    X_pos = X_test[i_pos,:]\n",
    "    #X_pos = X_pos.sample(n_pos)\n",
    "    X_pos[np.random.randint(X_pos.shape[0], size=n_pos),:]\n",
    "\n",
    "    \n",
    "\n",
    "    y_pos = np.full((1,n_pos), label)[0]\n",
    "\n",
    "    #X_neg = X_test.iloc[np.where(y_test != label)]\n",
    "    X_neg = X_test[np.where(y_test != label)[0],:]\n",
    "\n",
    "    dist_neg = np.random.uniform(0,1, len(np.unique(y_test))-1)\n",
    "    \n",
    "    dist_neg = dist_neg/np.sum(dist_neg)\n",
    "    \n",
    "    neg_labels = y_test[y_test != label]    \n",
    "\n",
    "    if alpha == 1.0:\n",
    "        dist_neg = np.array(dist_neg*(1-alpha))\n",
    "        test = X_pos\n",
    "        #dist_cl = np.zeros(len(y_test)+1)\n",
    "        #np.append(np.unique(y_test[y_test != label]), label)\n",
    "        dist_cl = np.append(dist_neg, alpha)[np.argsort(np.append(np.unique(neg_labels), label))]\n",
    "        return test, None, dist_cl    \n",
    "        \n",
    "    neg_n = np.random.choice(np.unique(neg_labels), n_neg, p=dist_neg)\n",
    "    labels, values = zip(*Counter(neg_n).items())    \n",
    "    \n",
    "    test = np.empty((0, X_neg.shape[1]))\n",
    "    for i in range(0,len(labels)):        \n",
    "        #aux = X_neg.iloc[np.where(neg_labels == labels[i])]\n",
    "        \n",
    "        aux = X_neg[np.where(neg_labels == labels[i])[0],:]\n",
    "\n",
    "        test = np.concatenate([test,aux[np.random.randint(aux.shape[0], size=values[i]),:]])\n",
    "        \n",
    "        \n",
    "        #test = pd.concat([test, aux.sample(values[i])], axis=0)\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    #test = pd.concat([test, X_pos], axis=0)\n",
    "    test = np.concatenate([test,X_pos[0]])  \n",
    "    dist_neg = np.array(dist_neg*(1-alpha))  \n",
    "    \n",
    "    dist_cl = np.append(dist_neg, alpha)[np.argsort(np.append(np.unique(neg_labels), label))]   \n",
    "\n",
    "    return test, np.append(np.array(neg_n), np.array(y_pos)), dist_cl\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_OVR(X_train, y_train, label):\n",
    "  train_pos = X_train[y_train == label,:]\n",
    "  train_neg = X_train[y_train != label,:]\n",
    "\n",
    "  #training_set = pd.concat([train_pos, train_neg], axis=0)\n",
    "  \n",
    "  training_set = np.concatenate((train_pos, train_neg)) \n",
    "  labels = np.zeros(len(y_train))\n",
    "  labels[y_train == label] = 1\n",
    "  labels = np.int0(labels)\n",
    "  return training_set, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expereiment(X_train, X_test, y_train, y_test, dts_name, models, l_scores):\n",
    "  #>>>>>>>..............Experimental_setup............>>>>>>>>>>\n",
    "  vdist = [\"topsoe\", \"jensen_difference\", \"prob_symm\", \"ord\", \"sord\", \"hellinger\"] \n",
    "  names_vdist = [\"TS\", \"JD\", \"PS\", \"ORD\", \"SORD\", \"HD\"] \n",
    "  counters    = ['DyS-TS']\n",
    "  measure     = \"topsoe\"                   #default measure for DyS\n",
    "  niterations = 10\n",
    "  alpha_values = [0,0.1,0.2,0.3,0.4,0.6,0.7,0.8,0.9,1]\n",
    "\n",
    "  y_test = pd.DataFrame(y_test)\n",
    "  n_classes = np.sort(np.int0(np.unique(y_train)))\n",
    "  print(n_classes)\n",
    "  \n",
    "  #X_test = X_test.reset_index()\n",
    "  #y_test = y_test.reset_index()\n",
    "  #y_test = y_test.drop(['index'], axis=1)\n",
    "  #X_test = X_test.drop(['index'], axis=1)  \n",
    "\n",
    "  #clf = RandomForestClassifier(n_estimators=200)\n",
    "  clf= svm.SVC()\n",
    "  \n",
    "  if models is None:\n",
    "    models = []\n",
    "    l_scores = []\n",
    "    l_train = []\n",
    "    l_ytrain= []\n",
    "    lbin = preprocessing.LabelBinarizer()\n",
    "    y_bin = lbin.fit_transform(y_train)\n",
    "    for ci in range(0,len(n_classes)):      \n",
    "      #train_bin, y_bin = training_OVR(np.array(X_train), y_train, ci)\n",
    "      clf.fit(X_train, y_bin[:,ci])\n",
    "      models.append(deepcopy(clf))\n",
    "      l_scores.append(qntu.getScores(X_train, y_bin[:,ci], 10, clf))\n",
    "      l_train.append(X_train)\n",
    "      l_ytrain.append(y_bin[:,ci])      \n",
    "\n",
    "    pickle.dump(models, open('./models_scores/'+dts_name+'/models.sav', 'wb'))\n",
    "    pickle.dump(l_scores, open('./models_scores/'+dts_name+'/l_scores.sav', 'wb'))\n",
    "    pickle.dump(l_train, open('./models_scores/'+dts_name+'/l_train.sav', 'wb'))\n",
    "    pickle.dump(l_ytrain, open('./models_scores/'+dts_name+'/l_ytrain.sav', 'wb'))\n",
    "  else:\n",
    "    models = pickle.load(open('./models_scores/'+dts_name+'/models.sav', 'rb'))\n",
    "    l_scores = pickle.load(open('./models_scores/'+dts_name+'/l_scores.sav', 'rb'))\n",
    "    l_train = pickle.load(open('./models_scores/'+dts_name+'/l_train.sav', 'rb'))\n",
    "    l_ytrain = pickle.load(open('./models_scores/'+dts_name+'/l_ytrain.sav', 'rb'))\n",
    "     \n",
    "  result = pd.DataFrame()   \n",
    "  \n",
    "  batch_sizes = [50]\n",
    "  table=pd.DataFrame()\n",
    "  for sample_size in batch_sizes:   #[10,100,500], batch_sizes, Varying test set sizes \n",
    "    for cl in n_classes:\n",
    "      for alpha in alpha_values:      \n",
    "        for iter in range(niterations):\n",
    "          #print('Sample size #%d' % (sample_size))\n",
    "          print('iteration #%d' % (iter + 1))\n",
    "          sample_test, _, prop_actual = get_batch(cl, alpha, X_test, y_test[0], sample_size)  \n",
    "          for co in counters:\n",
    "            aux = co.split(\"-\")\n",
    "            #print(co)\n",
    "            quantifier = co\n",
    "            if len(aux) > 1:\n",
    "              quantifier = aux[0]\n",
    "              measure = vdist[names_vdist.index(aux[1])]\n",
    "            \n",
    "            pred_dist = []\n",
    "\n",
    "            aux = co.split('_')\n",
    "            if len(aux) > 1:            \n",
    "              #qnt1 = fit_quantifier_schumacher_github(aux[1], X_train, y_train)\n",
    "              #pred_dist = predict_quantifier_schumacher_github(qnt1, sample_test) \n",
    "              pass\n",
    "            else:\n",
    "              for i in range(0, len(models)):\n",
    "                clf = models[i]   \n",
    "                #te_scores = clf.predict_proba(sample_test)[:,1]  #estimating test sample scores                \n",
    "                te_scores = clf.decision_function(sample_test)  #estimating test sample scores               \n",
    "                scores = l_scores[i]  \n",
    "                tprfpr = None#qntu.getTPRandFPRbyThreshold(scores)           \n",
    "                #.............Calling of Methods..................................................           \n",
    "                pos_scores = scores[scores['label']==1]['score']\n",
    "                neg_scores = scores[scores['label']==0]['score']\n",
    "                u_p = np.mean(pos_scores)\n",
    "                u_n = np.mean(neg_scores)\n",
    "\n",
    "                pred_pos_prop = apply_quantifier(qntMethod = quantifier, p_score = pos_scores, n_score = neg_scores, test_score = te_scores, \n",
    "                                                TprFpr = tprfpr, thr = 0.5, measure = measure, calib_clf = None, X_test = sample_test, \n",
    "                                                u_p = u_p, u_n = u_n)         \n",
    "              \n",
    "                pred_pos_prop = round(pred_pos_prop,2)  #predicted class proportion\n",
    "                pred_dist.append(pred_pos_prop)        \n",
    "                \n",
    "              #..............................RESULTS Evaluation.....................................\n",
    "            aux_sum = np.sum(pred_dist)\n",
    "            if aux_sum != 0.0:\n",
    "              pred_dist = pred_dist/aux_sum\n",
    "\n",
    "            pred_dist = np.round(pred_dist, 3)\n",
    "            #abs_error = np.round(np.sum(abs(pred_dist - prop_actual))/len(n_classes),3) #absolute error  \n",
    "            abs_error = np.round(np.sum(abs(pred_dist - prop_actual)),3)\n",
    "            #abs_error = qp.error.absolute_error(pred_dist, prop_actual)    \n",
    "            print(abs_error)\n",
    "\n",
    "            line_result = pd.concat([pd.DataFrame([sample_size, abs_error, quantifier, dts_name]).T, pd.DataFrame(np.array(prop_actual)).T, pd.DataFrame(np.array(pred_dist)).T], axis=1)\n",
    "\n",
    "            result = pd.concat([result, line_result], axis=0)\n",
    "\n",
    "    co_names = [\"Test_size\",\"abs_error\",\"quantifier\", \"dataset\"]\n",
    "    co_actual = [\"actual_c.\"+ str(x) for x in np.unique(n_classes)]\n",
    "    co_pred = [\"pred_c.\"+ str(x) for x in np.unique(n_classes)]\n",
    "    co_names.extend(co_actual)\n",
    "    co_names.extend(co_pred) \n",
    "\n",
    "    result.columns = co_names  \n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "iteration #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/cvxpy/problems/problem.py:1294: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m(96)\u001b[0;36mrun_expereiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 96 \u001b[0;31m                \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m                \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "0.38\n",
      "> \u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m(95)\u001b[0;36mrun_expereiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     93 \u001b[0;31m                                                u_p = u_p, u_n = u_n)         \n",
      "\u001b[0m\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 95 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m                \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m                \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** NameError: name 'abs_error' is not defined\n",
      "[0.38]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/cvxpy/problems/problem.py:1294: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m(96)\u001b[0;36mrun_expereiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 96 \u001b[0;31m                \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m                \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "[0.38, 1.0]\n",
      "0.2\n",
      "iteration #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/cvxpy/problems/problem.py:1294: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m(95)\u001b[0;36mrun_expereiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     93 \u001b[0;31m                                                u_p = u_p, u_n = u_n)         \n",
      "\u001b[0m\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 95 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     96 \u001b[0;31m                \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m                \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/cvxpy/problems/problem.py:1294: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m(96)\u001b[0;36mrun_expereiment\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     94 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     95 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 96 \u001b[0;31m                \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     97 \u001b[0;31m                \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     98 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "*** NameError: name 'error_abs' is not defined\n",
      "0.2\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-c887188f20fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrun_expereiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SkillCraft'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m in \u001b[0;36mrun_expereiment\u001b[0;34m(X_train, X_test, y_train, y_test, dts_name, models, l_scores)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-d167261f7f09>\u001b[0m in \u001b[0;36mrun_expereiment\u001b[0;34m(X_train, X_test, y_train, y_test, dts_name, models, l_scores)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpred_pos_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#predicted class proportion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mpred_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_pos_prop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"scores/SkillCraft/Row1/Class1/X_train.npy\")\n",
    "y_train = np.load(\"scores/SkillCraft/Row1/Class1/y_train.npy\")\n",
    "\n",
    "X_test = np.load(\"scores/SkillCraft/Row1/Class1/X_test.npy\")\n",
    "y_test = np.load(\"scores/SkillCraft/Row1/Class1/y_test.npy\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "run_expereiment(X_train, X_test, y_train, y_test, 'SkillCraft', None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_scores = pickle.load(open('./models_scores/'+'SkillCraft'+'/l_scores.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.264528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.218064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.452301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.616858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.079966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>-1.112218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>-1.009145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>-1.585663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1870</th>\n",
       "      <td>-1.583538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>-1.041483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1872 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score  label\n",
       "0    -1.264528      1\n",
       "1     0.218064      1\n",
       "2    -1.452301      1\n",
       "3    -0.616858      1\n",
       "4    -0.079966      1\n",
       "...        ...    ...\n",
       "1867 -1.112218      0\n",
       "1868 -1.009145      0\n",
       "1869 -1.585663      0\n",
       "1870 -1.583538      0\n",
       "1871 -1.041483      0\n",
       "\n",
       "[1872 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='score', ylabel='Count'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.histplot(data=l_scores[2], x='score', hue='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    936\n",
       "3    562\n",
       "1    374\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.169416</td>\n",
       "      <td>0.099522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021732</td>\n",
       "      <td>0.160142</td>\n",
       "      <td>0.253144</td>\n",
       "      <td>0.158444</td>\n",
       "      <td>0.550941</td>\n",
       "      <td>0.544980</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.347251</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.181809</td>\n",
       "      <td>0.223426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.195075</td>\n",
       "      <td>0.037449</td>\n",
       "      <td>0.264582</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053218</td>\n",
       "      <td>0.248951</td>\n",
       "      <td>0.282249</td>\n",
       "      <td>0.569724</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.088929</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.180356</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.100551</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.321354</td>\n",
       "      <td>0.333717</td>\n",
       "      <td>0.397422</td>\n",
       "      <td>0.236301</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.127283</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386364</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.299140</td>\n",
       "      <td>0.100830</td>\n",
       "      <td>0.251029</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138385</td>\n",
       "      <td>0.460284</td>\n",
       "      <td>0.211257</td>\n",
       "      <td>0.370201</td>\n",
       "      <td>0.271854</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.233022</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.061145</td>\n",
       "      <td>0.022363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.099532</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.055009</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332171</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.460111</td>\n",
       "      <td>0.155010</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.176086</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>0.061062</td>\n",
       "      <td>0.363847</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.025630</td>\n",
       "      <td>0.091808</td>\n",
       "      <td>0.645627</td>\n",
       "      <td>0.105525</td>\n",
       "      <td>0.244272</td>\n",
       "      <td>0.225869</td>\n",
       "      <td>0.603448</td>\n",
       "      <td>0.161552</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.192973</td>\n",
       "      <td>0.156841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.516723</td>\n",
       "      <td>0.190668</td>\n",
       "      <td>0.230366</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.091462</td>\n",
       "      <td>0.152892</td>\n",
       "      <td>0.531245</td>\n",
       "      <td>0.138019</td>\n",
       "      <td>0.265928</td>\n",
       "      <td>0.369871</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.364224</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.191290</td>\n",
       "      <td>0.093284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.00200</td>\n",
       "      <td>0.713690</td>\n",
       "      <td>0.607514</td>\n",
       "      <td>0.276289</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.088916</td>\n",
       "      <td>0.532503</td>\n",
       "      <td>0.128542</td>\n",
       "      <td>0.269134</td>\n",
       "      <td>0.328164</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.290078</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.544204</td>\n",
       "      <td>0.341340</td>\n",
       "      <td>0.555859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151725</td>\n",
       "      <td>0.150381</td>\n",
       "      <td>0.525340</td>\n",
       "      <td>0.116970</td>\n",
       "      <td>0.242508</td>\n",
       "      <td>0.324758</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.132669</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>0.270897</td>\n",
       "      <td>0.049471</td>\n",
       "      <td>0.177591</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.298304</td>\n",
       "      <td>0.087520</td>\n",
       "      <td>0.526393</td>\n",
       "      <td>0.121730</td>\n",
       "      <td>0.260630</td>\n",
       "      <td>0.235493</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.209893</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.207966</td>\n",
       "      <td>0.133868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>466 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1        2         3         4         5    6         7   \\\n",
       "0    0.454545  0.059524  0.00060  0.367136  0.169416  0.099522  0.0  0.021732   \n",
       "1    0.727273  0.119048  0.00025  0.195075  0.037449  0.264582  0.4  0.000000   \n",
       "2    0.477273  0.059524  0.00022  0.180356  0.047556  0.100551  0.5  0.032436   \n",
       "3    0.386364  0.071429  0.00064  0.299140  0.100830  0.251029  0.5  0.000000   \n",
       "4    0.431818  0.047619  0.00015  0.099532  0.000421  0.055009  0.3  0.000000   \n",
       "..        ...       ...      ...       ...       ...       ...  ...       ...   \n",
       "461  0.409091  0.166667  0.00200  0.331288  0.061062  0.363847  0.4  0.025630   \n",
       "462  0.363636  0.166667  0.00050  0.516723  0.190668  0.230366  0.7  0.091462   \n",
       "463  0.545455  0.083333  0.00200  0.713690  0.607514  0.276289  0.2  0.030166   \n",
       "464  0.522727  0.035714  0.00150  0.544204  0.341340  0.555859  1.0  0.151725   \n",
       "465  0.522727  0.166667  0.00045  0.270897  0.049471  0.177591  0.4  0.298304   \n",
       "\n",
       "           8         9         10        11        12        13        14  \\\n",
       "0    0.160142  0.253144  0.158444  0.550941  0.544980  0.344828  0.347251   \n",
       "1    0.053218  0.248951  0.282249  0.569724  0.383708  0.327586  0.088929   \n",
       "2    0.018386  0.321354  0.333717  0.397422  0.236301  0.396552  0.127283   \n",
       "3    0.138385  0.460284  0.211257  0.370201  0.271854  0.327586  0.233022   \n",
       "4    0.000000  0.332171  0.363639  0.460111  0.155010  0.310345  0.176086   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "461  0.091808  0.645627  0.105525  0.244272  0.225869  0.603448  0.161552   \n",
       "462  0.152892  0.531245  0.138019  0.265928  0.369871  0.500000  0.364224   \n",
       "463  0.088916  0.532503  0.128542  0.269134  0.328164  0.379310  0.290078   \n",
       "464  0.150381  0.525340  0.116970  0.242508  0.324758  0.431034  0.132669   \n",
       "465  0.087520  0.526393  0.121730  0.260630  0.235493  0.758621  0.209893   \n",
       "\n",
       "           15        16        17  \n",
       "0    0.384615  0.181809  0.223426  \n",
       "1    0.384615  0.000000  0.000000  \n",
       "2    0.692308  0.000000  0.000000  \n",
       "3    0.538462  0.061145  0.022363  \n",
       "4    0.461538  0.000000  0.035286  \n",
       "..        ...       ...       ...  \n",
       "461  0.692308  0.192973  0.156841  \n",
       "462  0.615385  0.191290  0.093284  \n",
       "463  0.538462  0.000000  0.000000  \n",
       "464  0.307692  0.000000  0.000000  \n",
       "465  0.769231  0.207966  0.133868  \n",
       "\n",
       "[466 rows x 18 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
